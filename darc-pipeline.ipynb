{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shlex\n",
    "\n",
    "BASE_DATA_DIRS = [\"videos\", \"images\", \"metadata\"]\n",
    "for modal in BASE_DATA_DIRS:\n",
    "    os.makedirs(os.path.join(f\"./data/{modal}/\"), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download all episodes of the specified show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "search_show_names = [\"The People of Paradise\", \"Quest Under Capricorn\", \"Life On Earth\",  \"The Private Life Of Plants\", \"Planet Earth\", \"The Hunt\"]\n",
    "\n",
    "search_show_name = search_show_names[4]\n",
    "csv_file_path = \"./data/darc-iarchive-wldoc-with-vid-durations.csv\"\n",
    "\n",
    "# video extract params\n",
    "downloaded_show_name = search_show_name.lower().replace(\" \", \"-\")\n",
    "image_zfill_mag, fps = 5, 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the requested show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 ./scripts/darc_download_shows.py \\\n",
    "    --file_path {csv_file_path} \\\n",
    "    --search_show_name {shlex.quote(search_show_name)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Images from Videos at 2 fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 ./scripts/darc_extract_video_images.py \\\n",
    "    --show_name {downloaded_show_name} \\\n",
    "    --image_zfill_mag {image_zfill_mag} \\\n",
    "    --fps {fps}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = f\"./data/images/{downloaded_show_name}\"\n",
    "\n",
    "# Image features\n",
    "vision_model = \"google/vit-base-patch16-224-in21k\"\n",
    "bs_vm, nw_vm = 24, 4\n",
    "\n",
    "!python3 ./scripts/darc_imagefolder_feature_extraction.py \\\n",
    "    --image_folder {image_folder} \\\n",
    "    --vision_model {vision_model} \\\n",
    "    --batch_size {bs_vm} \\\n",
    "    --num_workers {nw_vm}\n",
    "\n",
    "#python3 ./scripts/darc_imagefolder_feature_extraction.py --image_folder ./data/images/life-on-earth/ --vision_model \"google/vit-base-patch16-224-in21k\" --batch_size 24 --num_workers 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLIP CAPTIONING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image captions\n",
    "language_model = \"Salesforce/blip2-opt-2.7b\"\n",
    "bs_lm, nw_lm = 6, 6\n",
    "\n",
    "!python3 ./scripts/darc_imagefolder_textcaption_generation.py \\\n",
    "    --image_folder {image_folder} \\\n",
    "    --language_model {language_model} \\\n",
    "    --batch_size {bs_lm} \\\n",
    "    --num_workers {nw_lm}\n",
    "\n",
    "# python3 ./scripts/darc_imagefolder_textcaption_generation.py --image_folder ./data/images/life-on-earth/ --language_model \"Salesforce/blip2-opt-2.7b\" --batch_size 4 --num_workers 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI text embeddings from captions\n",
    "- While I didnt batch anything to get the LoE data I've implemented and used the openAI API parallel requests script provided by openAI. To use this you have to transfer the data into a jsonl format first (not shown here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python3 ./scripts/openai_api_request_parallel_processor.py \\\n",
    "  --requests_filepath \"./data/images/life-on-earth/captions_ep_all.jsonl\" \\\n",
    "  --request_url https://api.openai.com/v1/embeddings \\\n",
    "  --max_requests_per_minute 1500 \\\n",
    "  --max_tokens_per_minute 6250000 \\\n",
    "  --token_encoding_name cl100k_base \\\n",
    "  --max_attempts 5 \\\n",
    "  --logging_level 20 \\\n",
    "  --api_key \"YOUR-API-KEY\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
